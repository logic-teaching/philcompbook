{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9\n",
    "\n",
    "Today we introduce the polynomial time comptuable sets, which are often regarded as good contender for what is feasibly computable. \n",
    "\n",
    "There will be lots of classes today, and it will be useful to have at hand [the map](img/map-handout.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is Cobham, in one of the original articles on the subject:\n",
    "\n",
    "> The subject of my talk is perhaps most directly indicated by simply asking two questions: first, is it harder to multiply than to add? And second, why? I grant I have put the first of these questions rather loosely; nevertheless, I think that the answer, ought to be: *yes*. It is the second, which asks for a justification of this answer which provides the challenge ({cite}`Cobham1965-jz` p. 24)\n",
    "\n",
    "Here is Aaronson, a prominent complexity theorist:\n",
    "\n",
    "> I think of the polynomial-exponential gap as occupying a \"middle ground\" between two other sorts of gaps [...]  The trouble with small quantitative gaps is that they are too sensitive to \"mundane\" modeling choices and the details of technology. But the [other gaps have] the opposite problem: [of being] serenely *in*sensitive to distinctions that we actually care about, such as between finding a solution and verifying it [...] ({cite}`Aaronson2013-ek` p. 270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the distinctions we have come across so far are ostensibly inadequate to this task:\n",
    "\n",
    "- Addition and multiplication are trivially primitive recursive and hence computable. We spoke of the study of non-computable functions and sets as a study of level of difficulty, but on this measure both addition and multiplication are equally and maximally non-difficult. \n",
    "\n",
    "- If verifying a solution to a given task is computable, then so is finding the solution to a given task: one just brute force searches among all possible solutions and verifies as one proceeds whether it is a genuine solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The class P and EXP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition (worst case running time function of a machine)\n",
    "\n",
    "Suppose that a Turing machine $M$ halts on all inputs. \n",
    "\n",
    "Recall that the number of symbols is assumed to be finite. \n",
    "\n",
    "Then for each $n$, there are only finitely many strings of symbols of length $n$.\n",
    "\n",
    "For each $n$, let $f(n)$ be the maximum number of steps which machine $M$ takes to halt on inputs of length $n$.\n",
    "\n",
    "Then this running time function $f$ is *the worst-case running time function* of $M$. \n",
    "\n",
    "### Definition (polynomial vs. exponential time complexity of a machine)\n",
    "\n",
    "The worst-case running time $f$ is *polynomial* if there is a polynomial $p(n)$ and constant $n_0\\geq 0$ such that $f(n)\\leq c\\cdot p(n)$ for all $n\\geq n_0$. \n",
    "\n",
    "Since the first term of a polynomial on the natural numbers eventually dominates the other terms, this is equivalent to there being constants $k>0, n_0\\geq 0, c>0$ such that $f(n)\\leq c\\cdot n^k$ for all $n\\geq n_0$.\n",
    "\n",
    "Likewise, the worse-case running time $f$ is *exponential* if $k>0, n_0\\geq 0, c>0$ such that $f(n)\\leq c\\cdot 2^{n^k}$ for all $n\\geq n_0$.\n",
    "\n",
    "The Turing machine $M$ is itself said to be *polynomial-time* (resp. *exponential*) if its worst-case running time function is polynomial (resp. *exponential*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of polynomial running times\n",
    "\n",
    "- *Sweeping across and then halting*: Consider the Turing machine that just reads the input tape from left to right and then halts. This has running time $n$.\n",
    "\n",
    "- *Sweeping there and back and then halting*: Consider the Turing machine that just reads the input tape from left to right and then goes right to left back across the tape and halts at the first cell. This has running time $2n$.\n",
    "\n",
    "- *Making a duplicate of input*: Consider the Turing machine that duplicates its input tape by repeatedly sweeping from left to right and back and copying a single cell on each sweep. If the input has length $n$, it has to sweep $n$-many times and each sweep takes $2n$-steps, counting both back and forth. Then it has running time $2n\\cdot n = 2n^2$.\n",
    "\n",
    "### Examples of exponential running time \n",
    "\n",
    "- *From a string of $n$ ones, make a string of $2^n$ ones*: Consider the Turing machine that when given an input of $n$-many $1$'s, moves over to the right and writes two ones, and then sweeps back and forth doubling the second block of ones and crossing one off the first block of ones on each sweep. This has worst case running time $\\sum_{i=1}^n (2(2^i)^2+(n-i))$, which with a little patience you can see is equal to $1/6 (3 n^2 - 3 n + 4^{n + 2} - 16)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition (The class P, the class EXP)\n",
    "\n",
    "A set $A$ of strings from some finite alphabet is *polynomial time computable* or in the class *P* if there is a polynomial time machine which computes it.\n",
    "\n",
    "A set $A$ of strings from some finite alphabet is *exponential time computable* or in the class *EXP* if there is an exponential time machine which computes it.\n",
    "\n",
    "Note that in this definition we are concerned with sets rather than functions (there are analogous definitions for functions, but P and EXP are by tradition reserved for sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of problems in P:\n",
    "\n",
    "Here are some traditional examples, along with a word about why the example is indeed in P, although it should be flagged that this is a mere sketch and more work is needed to establish a polynomial bound:\n",
    "\n",
    "- *Whether there is a path $s$ to $t$ in a graph (i.e. graph traversal problem)*: just explore graph starting from $s$ and mark what you have explored and see when you are done if you have marked $t$.\n",
    "\n",
    "- *Whether two numbers are relatively prime (i.e. have no common divisor)*: apply Euclidean algorithm, which involves successively cutting the two numbers at least by half in alternate stages.\n",
    "\n",
    "- *Whether a string is a well-formed formula*: apply \"balance of parentheses\" test plus fact that \"no proper initial segment of a wff is a wff\". \n",
    "\n",
    "- *Whether a string is a proof*: check that each line is a well-formed formula, and then check that each line is an axiom or follows from earlier lines by rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposition: there is a problem in EXP but not P\n",
    "\n",
    "Let $C = \\{e: \\varphi_e(e)\\downarrow$ in $\\leq 2^e$ steps $\\}$.\n",
    "\n",
    "Then $C$ is in EXP but not in P.\n",
    "\n",
    "*Note*: there is a much harder and more general theorem, whose proof is similar to the one we offer, called the *Time hierarchy theorem* ({cite}`Sipser2012-jg` pp. 369 ff).\n",
    "\n",
    "*Proof*:\n",
    "\n",
    "If one pays close attention to the construction of the universal machine $\\varphi_{e_0}$, one sees that if $\\varphi_e(n)\\downarrow $ in $\\leq s$ steps, then $\\varphi_{e_0}(e,n)\\downarrow$ in $\\leq s^2$ steps.\n",
    "\n",
    "Note that if $s\\leq 2^e$, then $s^2 \\leq 2^{e^2}$, and so $C$ is in EXP. \n",
    "\n",
    "Suppose for reductio that $C$ was in P. \n",
    "\n",
    "Then the following program, call it $i$, has worst case running time which is polynomial:\n",
    "\n",
    "```\n",
    "def φ_i(n):\n",
    "    if n in C:                                # insert witness to C being in P\n",
    "        return φ_n(n)+1                       # call up universal machine\n",
    "    else:\n",
    "        return 0\n",
    "```\n",
    "\n",
    "Choose constants $c,k,n_0$ such that for all $n\\geq n_0$ one has that $\\varphi_i(n)\\downarrow$ in $\\leq c\\cdot n^k$ many steps. \n",
    "\n",
    "Without loss of generality, $i\\geq n_0$ and $i^k\\leq 2^i$. Otherwise by put a bunch of non-active states and instructions in $i$ to make it bigger. \n",
    "\n",
    "Then $i$ in $C$. \n",
    "\n",
    "But then by definition of $φ_i(i)$ we get that $φ_i(i)=φ_i(i)+1$, a contradiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The class NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "A set $A$ of strings in some finite alphabet is in the class *NP* if there is a polynomial $p$ and a polynomial time machine $\\varphi_i$ such that for all strings $x$\n",
    "\n",
    "$x$ in $A$ iff there is $y$ with $\\left|y\\right|\\leq p(\\left|x\\right|)$ such that $\\varphi_i(x,y)\\downarrow=1$.\n",
    "\n",
    "In this context, such a $y$ is said to be a *certificate* for $x$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fagin's Theorem (Machine independent characterization of NP)\n",
    "\n",
    "A set $A$ of finite models in some finite relational signature is in NP iff there is a an formula $\\varphi(R_1, \\ldots, R_n)$ of first-order logic with new relation symbols $R_1, \\ldots, R_n$ of various aritites such that $M$ in $A$ iff $M\\models \\exists \\; R_1, \\ldots, R_n\\; \\varphi(R_1, \\ldots, R_n)$.\n",
    "\n",
    "({cite}`Fagin1973-ah`, {cite}`Immerman2012-em` pp. 115 ff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of problems in NP\n",
    "\n",
    "- *Whether there is a path between nodes $s,t$ in a graph that visits each node exactly one (i.e. Hamiltonian path problem)*: simply say that there is a binary relation $<$ which linearly orders the graph such that $s$ is the first element in the ordering, and $t$ is the the last element in the ordering, and $x<y$ with no $x<y'<y$ only if there is an edge from $x$ to $y$. In this case, the ordering $<$ is the certificate.\n",
    "\n",
    "- *Whether a number is composite (i.e. not prime)*: view the number as a finite linear order $M$, and say that it has two non-empty subsets $X,Y$ each of which has more than one element such that $M$ has the same cardinality as $X\\times Y$, where you write that out in terms of an existential quantifier over a binary relation which encodes a bijection $f$ between $M$ and $X\\times Y$. In this case, the triple $X,Y,f$ is the certificate.\n",
    "\n",
    "- *Whether a formula of propositional logic is satisfiable*: view the formula as a mathematical function of its atomic formulas, and then say there is an assignment of the atomic formulas to zero and one such that the value of the formula is one. The assignment is the certificate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status and significance of P=NP\n",
    "\n",
    "It is unknown whether P=NP. It is likewise unknown whether NP=EXP. The majority prediction is that P $\\subsetneq$ NP $\\subsetneq$ EXP.\n",
    "\n",
    "The view adumbrated by Aaronson in the opening as to their being an intuitive difference between finding a solution and verifying that it is a solution would be borne out if \n",
    "\n",
    "1. P $\\neq$ NP\n",
    "2. P is a good analysis (explication) of the difficulty of verifying solutionhood\n",
    "3. NP is a good analysis (explication) of the difficulty of finding a solution \n",
    "\n",
    "Broadly similiar sentiments conclusions be found by quick glance at complexity theory texts:\n",
    "\n",
    "> When someone finally proves P $\\neq$ NP, this will truly show that mathematicians -- as well as other creative individuals-- cannot uniformly and feasibly be replaced by machine ({cite}`Immerman2012-em` p. 245)\n",
    "\n",
    "> Recognizing the correctness of an answer is often easier than coming up with the answer. Appreciating a Beethoven sonata is far easier than composing the sonata; verifying the solidity of a design for a suspension bridge is easier (to a civil engineer anyway!) than coming up with a good design; verifying the proof of a theorem is easier than coming up with a proof itself [...] and so forth. In such cases, coming up with the right answer seems to involve *exhaustive search* over an exponentially large set. The P versus NP question aks whether exhaustive search can be avoided in general ({cite}`Arora2009-wz` pp. 57-58).\n",
    "\n",
    "Obviously lots of attention has been paid to 1 by computer scientists and mathematicians, and rightly so.\n",
    "\n",
    "But I do not think that philosophers have paid sufficient attention to 2-3, and it is not obvious to me that a more capacious sense of 'verification' or 'recognition of correctness' can be sustained. I don't think that I have anything like a good contendor for a counterexample, but am merely suggesting that it is not obvious to me that there is a univocal sense of 'recognition of correctness' at work in e.g. Arora-Barak's sonota, bridge, and proof examples, although I recognize a notion of recognition of correctness in each.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Pressures on feasibility from both sides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Pressures to go down from P \n",
    "\n",
    "Consider Immerman's remarks in his book and his SEP article:\n",
    "\n",
    "> [Truly feasible] inqueries are the queries that can be computed exactly with an \"affordable\" amount of time and hardware, on all \"reasonably sized\" instances ({cite}`Immerman2012-em` p. 41).\n",
    "\n",
    "> Note that this ['truly feasible'] is not a mathematically defined class, but rather an intuitive notion of those problems that can be solved exactly, for all the instances of reasonable size, within a reasonable amount of time, using a computer that we can afford. [...] There are problems in P requiring $n^{1,000}$ time for problems of size n and thus not feasible. [...] The number of steps required for problems of size n [occurring in nature] tends to be less than $cn^k$ with small multiplicative constants $c$, and very small exponents, $k$, i.e., $k\\leq 2$ ({cite}`Immerman2021-cw` \\S{4.1}).\n",
    "\n",
    "Hence to the extent that one builds into the notion of feasibility not just the asympotic bounds, but the hardware and time constraints we actually have, one gets a proper subset of P as the candidate for true feasibility.\n",
    "\n",
    "But if one is building in constraints on what we can actually do, in the amount of life and time afforded us, one raises the concern of why asympotic bounds are appropriate at all. This is what Aaronson is worrying about at the end of his article:\n",
    "\n",
    "> But as a matter of logic, asymptotic statements need not have *any implications whatsoever* for the finite values of n (say, 10,000) that humans actually care about, nor can any finite amount of experimental data confirm or refute an asymptotic claim  ({cite}`Aaronson2013-ek` p. 312)\n",
    "\n",
    "Presumably part of the way to adjudicate this is to say that the $n$ and the $k$ in the bounds $n^k$ are playing two different roles: we want $n$ to vary since my input may be different than your input, but we want to set some upper bounds on $k$ since it may seem plausible that whatever our various inputs, we are bound beneth a $k$ power of them for some small $k$. But adjudicating this debate about the communicative content of asympotic results in complexity theory derserves more care than I am able to give it here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pressures to go up from P\n",
    "\n",
    "Consider the machine-independent chracterizations of P due to Cobham and discussed by Aaronson:\n",
    "\n",
    "A function $f:\\mathbb{N}^n\\rightarrow \\mathbb{N}$ is comptuable with worse case polynomial running time iff it is in the smallest class which\n",
    "\n",
    "1. contains the contains: pairing, addition, multiplcation, the number of bits in binary representation, projection, the bit function, slicing of a bit, and the smash function $x\\mapsto 2^{\\left|x\\right|^2}$. \n",
    "\n",
    "2. is closed under composition and bounded recursion, namely:\n",
    "\n",
    "$$\n",
    "g(x,k) = \\begin{cases}\n",
    "    f(g(x, \\lfloor \\frac{k}{2}\\rfloor )) & \\text{if $k>1$} \\\\ \n",
    "    x & \\text{if  $k=1$} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "provided that $\\left|f(x)\\right|\\leq \\left|x\\right|$.\n",
    "\n",
    "Suppose that one viewed this as being part of a successful conceptual analysis of truly feasible, issuing in a Church-like thesis:\n",
    "\n",
    "- A function is truly feasible iff it is in the class described by Coham.\n",
    "\n",
    "Then the \"easy direction\" of this would be again the right-to-left direction, and it would be warranted by inspection in the case of 1, and for 2 by observations such as the following:\n",
    "\n",
    "> So, too, the number of steps involved in the extraction of square roots, calculation of quotients, etc. can be bounded by polynomials in the length of the numbers involved, and this seems to be a property of simple functions in general ({cite}`Cobham1965-jz` p. 28).\n",
    "\n",
    "But if one takes this view, it is easy to see that P is a subset of the truly feasible functions. To the extent that one thinks that the other direction is hard, there will be pressure to go up, not down. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
